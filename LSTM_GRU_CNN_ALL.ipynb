{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "import string\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, LSTM, Embedding, Flatten, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv1D,GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import random as python_random\n",
    "np.random.seed(123) \n",
    "python_random.seed(123)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>description</th>\n",
       "      <th>product_category_wide</th>\n",
       "      <th>mrp</th>\n",
       "      <th>price</th>\n",
       "      <th>%discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I DO\" Signature Lace Cheeky Hipster with Gift...</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>Collections</td>\n",
       "      <td>With \"I DO\" emblazoned on this Hanky Panky lac...</td>\n",
       "      <td>panties</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I DO\" Signature Lace Cheeky Hipster with Gift...</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>Panties</td>\n",
       "      <td>With \"I DO\" emblazoned on this Hanky Panky lac...</td>\n",
       "      <td>panties</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'After Midnight' Lace Open Gusset G-String</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>Bridal Lingerie</td>\n",
       "      <td>Stretch signature lace fashions an alluring do...</td>\n",
       "      <td>other</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'After Midnight' Lace Open Gusset G-String</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>Sexy Lingerie</td>\n",
       "      <td>Stretch signature lace fashions an alluring do...</td>\n",
       "      <td>other</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'After Midnight' Lace Open Gusset G-String</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>Women's Panties</td>\n",
       "      <td>Stretch signature lace fashions an alluring do...</td>\n",
       "      <td>other</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name   brand_name product_category                                        description product_category_wide   mrp  price  %discount\n",
       "0  \"I DO\" Signature Lace Cheeky Hipster with Gift...  hanky panky      Collections  With \"I DO\" emblazoned on this Hanky Panky lac...               panties  40.0   40.0        0.0\n",
       "1  \"I DO\" Signature Lace Cheeky Hipster with Gift...  hanky panky          Panties  With \"I DO\" emblazoned on this Hanky Panky lac...               panties  40.0   40.0        0.0\n",
       "2         'After Midnight' Lace Open Gusset G-String  hanky panky  Bridal Lingerie  Stretch signature lace fashions an alluring do...                 other  27.0   27.0        0.0\n",
       "3         'After Midnight' Lace Open Gusset G-String  hanky panky    Sexy Lingerie  Stretch signature lace fashions an alluring do...                 other  27.0   27.0        0.0\n",
       "4         'After Midnight' Lace Open Gusset G-String  hanky panky  Women's Panties  Stretch signature lace fashions an alluring do...                 other  27.0   27.0        0.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_data = pd.read_csv('Dataset/Intermediate/all_products.csv')\n",
    "products_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>description</th>\n",
       "      <th>product_category_wide</th>\n",
       "      <th>mrp</th>\n",
       "      <th>price</th>\n",
       "      <th>%discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"i do\" signature lace cheeky hipster with gift...</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>Collections</td>\n",
       "      <td>with \"i do\" emblazoned on this hanky panky lac...</td>\n",
       "      <td>panties</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"i do\" signature lace cheeky hipster with gift...</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>Panties</td>\n",
       "      <td>with \"i do\" emblazoned on this hanky panky lac...</td>\n",
       "      <td>panties</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'after midnight' lace open gusset g-string</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>Bridal Lingerie</td>\n",
       "      <td>stretch signature lace fashions an alluring do...</td>\n",
       "      <td>other</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'after midnight' lace open gusset g-string</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>Sexy Lingerie</td>\n",
       "      <td>stretch signature lace fashions an alluring do...</td>\n",
       "      <td>other</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'after midnight' lace open gusset g-string</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>Women's Panties</td>\n",
       "      <td>stretch signature lace fashions an alluring do...</td>\n",
       "      <td>other</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name   brand_name product_category                                        description product_category_wide   mrp  price  %discount\n",
       "0  \"i do\" signature lace cheeky hipster with gift...  hanky panky      Collections  with \"i do\" emblazoned on this hanky panky lac...               panties  40.0   40.0        0.0\n",
       "1  \"i do\" signature lace cheeky hipster with gift...  hanky panky          Panties  with \"i do\" emblazoned on this hanky panky lac...               panties  40.0   40.0        0.0\n",
       "2         'after midnight' lace open gusset g-string  hanky panky  Bridal Lingerie  stretch signature lace fashions an alluring do...                 other  27.0   27.0        0.0\n",
       "3         'after midnight' lace open gusset g-string  hanky panky    Sexy Lingerie  stretch signature lace fashions an alluring do...                 other  27.0   27.0        0.0\n",
       "4         'after midnight' lace open gusset g-string  hanky panky  Women's Panties  stretch signature lace fashions an alluring do...                 other  27.0   27.0        0.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_data['description'] = products_data['description'].str.lower()\n",
    "products_data['product_name'] = products_data['product_name'].str.lower()\n",
    "products_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5982, 8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3446, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_category_wide</th>\n",
       "      <th>description</th>\n",
       "      <th>mrp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"i do\" signature lace cheeky hipster with gift...</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>panties</td>\n",
       "      <td>with \"i do\" emblazoned on this hanky panky lac...</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'after midnight' lace open gusset g-string</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>other</td>\n",
       "      <td>stretch signature lace fashions an alluring do...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'after midnight' open gusset lace thong</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>panties</td>\n",
       "      <td>leopard-spotted lace adds to the bold open-gus...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'annabelle' lace camisole</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>camisoles</td>\n",
       "      <td>scalloped trim adorned with a little blue bow ...</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'annabelle' lace garter</td>\n",
       "      <td>hanky panky</td>\n",
       "      <td>other</td>\n",
       "      <td>scalloped lace adorned with a little blue bow ...</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name   brand_name product_category_wide                                        description   mrp\n",
       "0  \"i do\" signature lace cheeky hipster with gift...  hanky panky               panties  with \"i do\" emblazoned on this hanky panky lac...  40.0\n",
       "2         'after midnight' lace open gusset g-string  hanky panky                 other  stretch signature lace fashions an alluring do...  27.0\n",
       "5            'after midnight' open gusset lace thong  hanky panky               panties  leopard-spotted lace adds to the bold open-gus...  24.0\n",
       "8                          'annabelle' lace camisole  hanky panky             camisoles  scalloped trim adorned with a little blue bow ...  64.0\n",
       "9                            'annabelle' lace garter  hanky panky                 other  scalloped lace adorned with a little blue bow ...  23.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_data = products_data[['product_name', 'brand_name', 'product_category_wide', 'description', 'mrp']]\n",
    "products_data.drop_duplicates(inplace = True)\n",
    "print(products_data.shape)\n",
    "products_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords removal\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
    "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
    "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
    "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
    "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
    "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
    "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
    "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "             \"your\", \"yours\", \"yourself\", \"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_category_wide</th>\n",
       "      <th>description</th>\n",
       "      <th>mrp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"i do\" signature lace cheeky hipster with gift...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>with \"i do\" emblazoned on this hanky panky lac...</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'after midnight' lace open gusset g-string</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>stretch signature lace fashions an alluring do...</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'after midnight' open gusset lace thong</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>leopard-spotted lace adds to the bold open-gus...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'annabelle' lace camisole</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>scalloped trim adorned with a little blue bow ...</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'annabelle' lace garter</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>scalloped lace adorned with a little blue bow ...</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name  brand_name  product_category_wide                                        description   mrp\n",
       "0  \"i do\" signature lace cheeky hipster with gift...           6                      7  with \"i do\" emblazoned on this hanky panky lac...  40.0\n",
       "2         'after midnight' lace open gusset g-string           6                      6  stretch signature lace fashions an alluring do...  27.0\n",
       "5            'after midnight' open gusset lace thong           6                      7  leopard-spotted lace adds to the bold open-gus...  24.0\n",
       "8                          'annabelle' lace camisole           6                      5  scalloped trim adorned with a little blue bow ...  64.0\n",
       "9                            'annabelle' lace garter           6                      6  scalloped lace adorned with a little blue bow ...  23.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(np.hstack([products_data.product_category_wide]))\n",
    "products_data.product_category_wide = le.transform(products_data.product_category_wide)\n",
    "\n",
    "le.fit(np.hstack([products_data.brand_name]))\n",
    "products_data.brand_name = le.transform(products_data.brand_name)\n",
    "del le\n",
    "\n",
    "products_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_category_wide</th>\n",
       "      <th>mrp</th>\n",
       "      <th>clean_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"i do\" signature lace cheeky hipster with gift...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>i do  emblazoned hanky panky lace hipster swa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'after midnight' lace open gusset g-string</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>27.0</td>\n",
       "      <td>stretch signature lace fashions alluring doubl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'after midnight' open gusset lace thong</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>leopard spotted lace adds bold open gusset des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'annabelle' lace camisole</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>scalloped trim adorned little blue bow flirts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'annabelle' lace garter</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>scalloped lace adorned little blue bow defines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name  brand_name  product_category_wide   mrp                                  clean_description\n",
       "0  \"i do\" signature lace cheeky hipster with gift...           6                      7  40.0   i do  emblazoned hanky panky lace hipster swa...\n",
       "2         'after midnight' lace open gusset g-string           6                      6  27.0  stretch signature lace fashions alluring doubl...\n",
       "5            'after midnight' open gusset lace thong           6                      7  24.0  leopard spotted lace adds bold open gusset des...\n",
       "8                          'annabelle' lace camisole           6                      5  64.0  scalloped trim adorned little blue bow flirts ...\n",
       "9                            'annabelle' lace garter           6                      6  23.0  scalloped lace adorned little blue bow defines..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(data):\n",
    "  data['clean_description'] = data['description'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "  return data\n",
    "\n",
    "data_cleaned = remove_stopwords(products_data)\n",
    "data_cleaned['clean_description'] = data_cleaned['clean_description'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "data_cleaned.drop('description', inplace = True, axis = 1)\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Value of Sequences:  91 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_category_wide</th>\n",
       "      <th>mrp</th>\n",
       "      <th>clean_description</th>\n",
       "      <th>seq_description</th>\n",
       "      <th>seq_product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"i do\" signature lace cheeky hipster with gift...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>i do  emblazoned hanky panky lace hipster swa...</td>\n",
       "      <td>[540, 541, 1760, 83, 90, 1, 98, 1201, 557, 296...</td>\n",
       "      <td>[540, 541, 70, 1, 175, 98, 283, 439, 561]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'after midnight' lace open gusset g-string</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>27.0</td>\n",
       "      <td>stretch signature lace fashions alluring doubl...</td>\n",
       "      <td>[34, 70, 1, 1035, 612, 542, 174, 415, 246, 109...</td>\n",
       "      <td>[2569, 2570, 1, 211, 397, 415, 246]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'after midnight' open gusset lace thong</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>leopard spotted lace adds bold open gusset des...</td>\n",
       "      <td>[182, 691, 1, 416, 724, 211, 397, 135, 644, 49...</td>\n",
       "      <td>[2569, 2570, 211, 397, 1, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'annabelle' lace camisole</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>scalloped trim adorned little blue bow flirts ...</td>\n",
       "      <td>[302, 75, 1406, 340, 285, 156, 2620, 521, 77, ...</td>\n",
       "      <td>[2571, 1, 426]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'annabelle' lace garter</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>scalloped lace adorned little blue bow defines...</td>\n",
       "      <td>[302, 1, 1406, 340, 285, 156, 1990, 1407, 1109...</td>\n",
       "      <td>[2571, 1, 288]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name  brand_name  product_category_wide   mrp                                  clean_description                                    seq_description                           seq_product_name\n",
       "0  \"i do\" signature lace cheeky hipster with gift...           6                      7  40.0   i do  emblazoned hanky panky lace hipster swa...  [540, 541, 1760, 83, 90, 1, 98, 1201, 557, 296...  [540, 541, 70, 1, 175, 98, 283, 439, 561]\n",
       "2         'after midnight' lace open gusset g-string           6                      6  27.0  stretch signature lace fashions alluring doubl...  [34, 70, 1, 1035, 612, 542, 174, 415, 246, 109...        [2569, 2570, 1, 211, 397, 415, 246]\n",
       "5            'after midnight' open gusset lace thong           6                      7  24.0  leopard spotted lace adds bold open gusset des...  [182, 691, 1, 416, 724, 211, 397, 135, 644, 49...               [2569, 2570, 211, 397, 1, 8]\n",
       "8                          'annabelle' lace camisole           6                      5  64.0  scalloped trim adorned little blue bow flirts ...  [302, 75, 1406, 340, 285, 156, 2620, 521, 77, ...                             [2571, 1, 426]\n",
       "9                            'annabelle' lace garter           6                      6  23.0  scalloped lace adorned little blue bow defines...  [302, 1, 1406, 340, 285, 156, 1990, 1407, 1109...                             [2571, 1, 288]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing\n",
    "raw_text = np.hstack([data_cleaned.clean_description.str.lower(), data_cleaned.product_name.str.lower()])\n",
    "tok_raw = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tok_raw.fit_on_texts(raw_text)\n",
    "data_cleaned[\"seq_description\"] = tok_raw.texts_to_sequences(data_cleaned.clean_description.str.lower())\n",
    "data_cleaned[\"seq_product_name\"] = tok_raw.texts_to_sequences(data_cleaned.product_name.str.lower())\n",
    "max_seq_description = np.max(data_cleaned.seq_description.apply(lambda x: len(x)))\n",
    "max_seq_product_name = np.max(data_cleaned.seq_product_name.apply(lambda x: len(x)))\n",
    "print(\"Maximum Value of Sequences: \", max_seq_description, max_seq_product_name)\n",
    "\n",
    "MAX_TEXT = np.max([np.max(data_cleaned.seq_description.apply(lambda x : max(x))),\n",
    "                   np.max(data_cleaned.seq_product_name.apply(lambda x : max(x)))])  + 3\n",
    "\n",
    "MAX_BRAND = np.max(data_cleaned.brand_name.max()) + 3\n",
    "MAX_CAT = np.max(data_cleaned.product_category_wide.max()) + 3\n",
    "\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'target'}>]], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Min Max Scaler for target\n",
    "data_cleaned[\"target\"] = np.log(data_cleaned.mrp+1)\n",
    "target_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "data_cleaned[\"target\"] = target_scaler.fit_transform(data_cleaned.target.values.reshape(-1,1))\n",
    "pd.DataFrame(data_cleaned.target).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3101, 8)\n",
      "(345, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_category_wide</th>\n",
       "      <th>mrp</th>\n",
       "      <th>clean_description</th>\n",
       "      <th>seq_description</th>\n",
       "      <th>seq_product_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4479</th>\n",
       "      <td>seamless hipster briefs</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>13.00</td>\n",
       "      <td>ultrasoft  stretchy microfiber shapes comforta...</td>\n",
       "      <td>[1688, 49, 389, 694, 95, 98, 208, 1933, 303, 3...</td>\n",
       "      <td>[48, 98, 208]</td>\n",
       "      <td>-0.690375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>bridget pushup cotton bra</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32.95</td>\n",
       "      <td>flirt everyday perkiness every girl  style  97...</td>\n",
       "      <td>[569, 73, 630, 89, 159, 5, 1070, 1639, 9, 933,...</td>\n",
       "      <td>[643, 66, 7, 2]</td>\n",
       "      <td>-0.294680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>aerie everyday loves lace thong</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12.50</td>\n",
       "      <td>introducing everyday loves™  made love  everyd...</td>\n",
       "      <td>[356, 73, 357, 32, 39, 73, 116, 258, 234, 140,...</td>\n",
       "      <td>[14, 73, 116, 1, 8]</td>\n",
       "      <td>-0.706620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>aerie bikini</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9.50</td>\n",
       "      <td>peek cheek  lot wow  soft comfy cotton love fi...</td>\n",
       "      <td>[27, 26, 230, 207, 18, 20, 7, 39, 23, 65, 87, ...</td>\n",
       "      <td>[14, 38]</td>\n",
       "      <td>-0.818881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>id logo mesh-panel hipster qf1780</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>22.00</td>\n",
       "      <td>kick style notch logo enhanced cooling hipster...</td>\n",
       "      <td>[1690, 5, 2943, 35, 701, 1889, 98, 54, 59]</td>\n",
       "      <td>[406, 35, 36, 364, 98, 3654]</td>\n",
       "      <td>-0.468620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           product_name  brand_name  product_category_wide    mrp                                  clean_description                                    seq_description              seq_product_name    target\n",
       "4479            seamless hipster briefs           9                      7  13.00  ultrasoft  stretchy microfiber shapes comforta...  [1688, 49, 389, 694, 95, 98, 208, 1933, 303, 3...                 [48, 98, 208] -0.690375\n",
       "2199          bridget pushup cotton bra           0                      4  32.95  flirt everyday perkiness every girl  style  97...  [569, 73, 630, 89, 159, 5, 1070, 1639, 9, 933,...               [643, 66, 7, 2] -0.294680\n",
       "843     aerie everyday loves lace thong           0                      7  12.50  introducing everyday loves™  made love  everyd...  [356, 73, 357, 32, 39, 73, 116, 258, 234, 140,...           [14, 73, 116, 1, 8] -0.706620\n",
       "324                        aerie bikini           0                      6   9.50  peek cheek  lot wow  soft comfy cotton love fi...  [27, 26, 230, 207, 18, 20, 7, 39, 23, 65, 87, ...                      [14, 38] -0.818881\n",
       "3247  id logo mesh-panel hipster qf1780           2                      7  22.00  kick style notch logo enhanced cooling hipster...         [1690, 5, 2943, 35, 701, 1889, 98, 54, 59]  [406, 35, 36, 364, 98, 3654] -0.468620"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Test Split\n",
    "dtrain, dtest = train_test_split(data_cleaned, random_state=123, train_size=0.90)\n",
    "print(dtrain.shape)\n",
    "print(dtest.shape)\n",
    "dtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_name': array([[   0,    0,    0, ...,   48,   98,  208],\n",
       "        [   0,    0,    0, ...,   66,    7,    2],\n",
       "        [   0,    0,    0, ...,  116,    1,    8],\n",
       "        ...,\n",
       "        [   0,  165,  133, ...,  288,  452, 3534],\n",
       "        [   0,    0,    0, ...,  833,   19, 3582],\n",
       "        [   0,    0,    0, ...,  118,  132,    2]]),\n",
       " 'item_desc': array([[   0,    0,    0, ...,   62,  304,   23],\n",
       "        [   0,    0,    0, ...,    3,    3,   11],\n",
       "        [   0,    0,    0, ...,    3,    3,   11],\n",
       "        ...,\n",
       "        [   0,    0,    0, ...,  133,   54,   59],\n",
       "        [   0,    0,    0, ...,  238,  243,  135],\n",
       "        [   0,    0,    0, ...,  264,  837, 1243]]),\n",
       " 'brand_name': array([9, 0, 0, ..., 2, 6, 2]),\n",
       " 'product_category': array([ 7,  4,  7, ..., 12,  3,  4])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequence Padding\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'item_name':  pad_sequences(dataset.seq_product_name, maxlen=10),\n",
    "        'item_desc': pad_sequences(dataset.seq_description, maxlen=75),\n",
    "        'brand_name': np.array(dataset.brand_name),\n",
    "        'product_category': np.array(dataset.product_category_wide)\n",
    "    }\n",
    "    return X\n",
    "\n",
    "X_train = get_keras_data(dtrain)\n",
    "X_test = get_keras_data(dtest)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " item_desc (InputLayer)         [(None, 75)]         0           []                               \n",
      "                                                                                                  \n",
      " item_name (InputLayer)         [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " brand_name (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " product_category (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_25 (Embedding)       (None, 75, 50)       195500      ['item_desc[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_24 (Embedding)       (None, 10, 50)       195500      ['item_name[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_26 (Embedding)       (None, 1, 10)        160         ['brand_name[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_27 (Embedding)       (None, 1, 10)        160         ['product_category[0][0]']       \n",
      "                                                                                                  \n",
      " gru_4 (GRU)                    (None, 16)           3264        ['embedding_25[0][0]']           \n",
      "                                                                                                  \n",
      " gru_5 (GRU)                    (None, 8)            1440        ['embedding_24[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)           (None, 10)           0           ['embedding_26[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_13 (Flatten)           (None, 10)           0           ['embedding_27[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 44)           0           ['gru_4[0][0]',                  \n",
      "                                                                  'gru_5[0][0]',                  \n",
      "                                                                  'flatten_12[0][0]',             \n",
      "                                                                  'flatten_13[0][0]']             \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          5760        ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 128)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 64)           8256        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 64)           0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 1)            65          ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 410,105\n",
      "Trainable params: 410,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "def rmsle_cust(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n",
    "\n",
    "def get_gru_model():\n",
    "    # Params\n",
    "    dr_r = 0.1\n",
    "    \n",
    "    # Inputs\n",
    "    item_name = Input(shape=[X_train[\"item_name\"].shape[1]], name=\"item_name\")\n",
    "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    product_category = Input(shape=[1], name=\"product_category\")\n",
    "    \n",
    "    # Embeddings Layers\n",
    "    emb_item_name = Embedding(MAX_TEXT, 50)(item_name)\n",
    "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    emb_product_category = Embedding(MAX_CAT, 10)(product_category)\n",
    "    \n",
    "    # RNN Layer\n",
    "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
    "    rnn_layer2 = GRU(8) (emb_item_name)\n",
    "    \n",
    "    # Main Layer\n",
    "    main_l = concatenate([\n",
    "        rnn_layer1,\n",
    "        rnn_layer2,\n",
    "        Flatten() (emb_brand_name)\n",
    "        , Flatten() (emb_product_category)\n",
    "    ])\n",
    "    main_l = Dropout(dr_r) (Dense(128) (main_l))\n",
    "    main_l = Dropout(dr_r) (Dense(64) (main_l))\n",
    "    \n",
    "    # Output Layer\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    # Init Model\n",
    "    model = Model([item_name, item_desc, brand_name, product_category], output)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "gru_model = get_gru_model()\n",
    "\n",
    "# Calculation of Loss History\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "history = LossHistory()\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 5s 913ms/step - loss: 0.1878 - mae: 0.3589 - rmsle_cust: 0.0141 - val_loss: 0.1200 - val_mae: 0.2727 - val_rmsle_cust: 0.0077\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 1s 191ms/step - loss: 0.1267 - mae: 0.2824 - rmsle_cust: 0.0101 - val_loss: 0.0784 - val_mae: 0.2174 - val_rmsle_cust: 0.0077\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 1s 205ms/step - loss: 0.0835 - mae: 0.2252 - rmsle_cust: 0.0101 - val_loss: 0.0582 - val_mae: 0.1976 - val_rmsle_cust: 0.0077\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 1s 193ms/step - loss: 0.0627 - mae: 0.2047 - rmsle_cust: 0.0101 - val_loss: 0.0599 - val_mae: 0.2085 - val_rmsle_cust: 0.0077\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 1s 196ms/step - loss: 0.0622 - mae: 0.2093 - rmsle_cust: 0.0101 - val_loss: 0.0595 - val_mae: 0.2078 - val_rmsle_cust: 0.0077\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 1s 198ms/step - loss: 0.0600 - mae: 0.2053 - rmsle_cust: 0.0101 - val_loss: 0.0466 - val_mae: 0.1816 - val_rmsle_cust: 0.0077\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.0465 - mae: 0.1779 - rmsle_cust: 0.0101 - val_loss: 0.0344 - val_mae: 0.1511 - val_rmsle_cust: 0.0077\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 1s 209ms/step - loss: 0.0350 - mae: 0.1487 - rmsle_cust: 0.0101 - val_loss: 0.0299 - val_mae: 0.1344 - val_rmsle_cust: 0.0077\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 1s 209ms/step - loss: 0.0317 - mae: 0.1372 - rmsle_cust: 0.0099 - val_loss: 0.0283 - val_mae: 0.1297 - val_rmsle_cust: 0.0074\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 1s 196ms/step - loss: 0.0289 - mae: 0.1325 - rmsle_cust: 0.0093 - val_loss: 0.0238 - val_mae: 0.1191 - val_rmsle_cust: 0.0071\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 1s 233ms/step - loss: 0.0239 - mae: 0.1202 - rmsle_cust: 0.0092 - val_loss: 0.0185 - val_mae: 0.1017 - val_rmsle_cust: 0.0070\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 1s 209ms/step - loss: 0.0186 - mae: 0.1013 - rmsle_cust: 0.0092 - val_loss: 0.0170 - val_mae: 0.0956 - val_rmsle_cust: 0.0068\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 1s 207ms/step - loss: 0.0175 - mae: 0.0955 - rmsle_cust: 0.0089 - val_loss: 0.0180 - val_mae: 0.0995 - val_rmsle_cust: 0.0068\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 0.0187 - mae: 0.0994 - rmsle_cust: 0.0088 - val_loss: 0.0167 - val_mae: 0.0955 - val_rmsle_cust: 0.0070\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 1s 198ms/step - loss: 0.0169 - mae: 0.0946 - rmsle_cust: 0.0090 - val_loss: 0.0144 - val_mae: 0.0898 - val_rmsle_cust: 0.0083\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 0.0135 - mae: 0.0851 - rmsle_cust: 0.0097 - val_loss: 0.0142 - val_mae: 0.0926 - val_rmsle_cust: 0.0089\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 1s 210ms/step - loss: 0.0125 - mae: 0.0839 - rmsle_cust: 0.0097 - val_loss: 0.0140 - val_mae: 0.0933 - val_rmsle_cust: 0.0083\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 0.0121 - mae: 0.0831 - rmsle_cust: 0.0088 - val_loss: 0.0127 - val_mae: 0.0870 - val_rmsle_cust: 0.0070\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 1s 231ms/step - loss: 0.0101 - mae: 0.0734 - rmsle_cust: 0.0072 - val_loss: 0.0116 - val_mae: 0.0807 - val_rmsle_cust: 0.0061\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 1s 202ms/step - loss: 0.0092 - mae: 0.0683 - rmsle_cust: 0.0064 - val_loss: 0.0117 - val_mae: 0.0805 - val_rmsle_cust: 0.0061\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.0090 - mae: 0.0685 - rmsle_cust: 0.0061 - val_loss: 0.0118 - val_mae: 0.0808 - val_rmsle_cust: 0.0061\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 1s 198ms/step - loss: 0.0086 - mae: 0.0680 - rmsle_cust: 0.0061 - val_loss: 0.0112 - val_mae: 0.0785 - val_rmsle_cust: 0.0061\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 1s 193ms/step - loss: 0.0079 - mae: 0.0636 - rmsle_cust: 0.0057 - val_loss: 0.0108 - val_mae: 0.0768 - val_rmsle_cust: 0.0061\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 1s 207ms/step - loss: 0.0073 - mae: 0.0601 - rmsle_cust: 0.0054 - val_loss: 0.0109 - val_mae: 0.0775 - val_rmsle_cust: 0.0061\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 1s 197ms/step - loss: 0.0071 - mae: 0.0598 - rmsle_cust: 0.0057 - val_loss: 0.0109 - val_mae: 0.0776 - val_rmsle_cust: 0.0060\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 1s 202ms/step - loss: 0.0068 - mae: 0.0592 - rmsle_cust: 0.0056 - val_loss: 0.0104 - val_mae: 0.0750 - val_rmsle_cust: 0.0060\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 1s 208ms/step - loss: 0.0066 - mae: 0.0578 - rmsle_cust: 0.0059 - val_loss: 0.0100 - val_mae: 0.0733 - val_rmsle_cust: 0.0059\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 1s 219ms/step - loss: 0.0061 - mae: 0.0558 - rmsle_cust: 0.0057 - val_loss: 0.0098 - val_mae: 0.0729 - val_rmsle_cust: 0.0059\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.0060 - mae: 0.0551 - rmsle_cust: 0.0053 - val_loss: 0.0096 - val_mae: 0.0718 - val_rmsle_cust: 0.0058\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 0.0057 - mae: 0.0533 - rmsle_cust: 0.0054 - val_loss: 0.0095 - val_mae: 0.0708 - val_rmsle_cust: 0.0058\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 1s 213ms/step - loss: 0.0055 - mae: 0.0528 - rmsle_cust: 0.0055 - val_loss: 0.0094 - val_mae: 0.0706 - val_rmsle_cust: 0.0058\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 1s 214ms/step - loss: 0.0053 - mae: 0.0512 - rmsle_cust: 0.0052 - val_loss: 0.0093 - val_mae: 0.0700 - val_rmsle_cust: 0.0057\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.0052 - mae: 0.0509 - rmsle_cust: 0.0050 - val_loss: 0.0091 - val_mae: 0.0688 - val_rmsle_cust: 0.0057\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 1s 222ms/step - loss: 0.0049 - mae: 0.0488 - rmsle_cust: 0.0046 - val_loss: 0.0090 - val_mae: 0.0676 - val_rmsle_cust: 0.0057\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.0048 - mae: 0.0486 - rmsle_cust: 0.0045 - val_loss: 0.0089 - val_mae: 0.0671 - val_rmsle_cust: 0.0056\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 1s 207ms/step - loss: 0.0047 - mae: 0.0480 - rmsle_cust: 0.0045 - val_loss: 0.0089 - val_mae: 0.0667 - val_rmsle_cust: 0.0055\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 1s 207ms/step - loss: 0.0045 - mae: 0.0474 - rmsle_cust: 0.0042 - val_loss: 0.0088 - val_mae: 0.0666 - val_rmsle_cust: 0.0055\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 1s 198ms/step - loss: 0.0045 - mae: 0.0473 - rmsle_cust: 0.0041 - val_loss: 0.0088 - val_mae: 0.0666 - val_rmsle_cust: 0.0055\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 1s 191ms/step - loss: 0.0042 - mae: 0.0457 - rmsle_cust: 0.0040 - val_loss: 0.0088 - val_mae: 0.0664 - val_rmsle_cust: 0.0055\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 1s 197ms/step - loss: 0.0042 - mae: 0.0457 - rmsle_cust: 0.0040 - val_loss: 0.0087 - val_mae: 0.0663 - val_rmsle_cust: 0.0055\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 1s 187ms/step - loss: 0.0041 - mae: 0.0448 - rmsle_cust: 0.0040 - val_loss: 0.0087 - val_mae: 0.0661 - val_rmsle_cust: 0.0054\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 1s 218ms/step - loss: 0.0040 - mae: 0.0449 - rmsle_cust: 0.0040 - val_loss: 0.0087 - val_mae: 0.0658 - val_rmsle_cust: 0.0054\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 0.0038 - mae: 0.0434 - rmsle_cust: 0.0038 - val_loss: 0.0087 - val_mae: 0.0655 - val_rmsle_cust: 0.0054\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 1s 196ms/step - loss: 0.0037 - mae: 0.0427 - rmsle_cust: 0.0037 - val_loss: 0.0087 - val_mae: 0.0653 - val_rmsle_cust: 0.0054\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 1s 213ms/step - loss: 0.0038 - mae: 0.0433 - rmsle_cust: 0.0038 - val_loss: 0.0086 - val_mae: 0.0650 - val_rmsle_cust: 0.0054\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 1s 207ms/step - loss: 0.0036 - mae: 0.0424 - rmsle_cust: 0.0036 - val_loss: 0.0086 - val_mae: 0.0651 - val_rmsle_cust: 0.0054\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 218ms/step - loss: 0.0036 - mae: 0.0421 - rmsle_cust: 0.0035 - val_loss: 0.0086 - val_mae: 0.0651 - val_rmsle_cust: 0.0054\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 1s 218ms/step - loss: 0.0036 - mae: 0.0423 - rmsle_cust: 0.0035 - val_loss: 0.0086 - val_mae: 0.0650 - val_rmsle_cust: 0.0055\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 1s 216ms/step - loss: 0.0035 - mae: 0.0414 - rmsle_cust: 0.0035 - val_loss: 0.0086 - val_mae: 0.0649 - val_rmsle_cust: 0.0056\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 1s 232ms/step - loss: 0.0034 - mae: 0.0411 - rmsle_cust: 0.0036 - val_loss: 0.0085 - val_mae: 0.0648 - val_rmsle_cust: 0.0057\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 1s 232ms/step - loss: 0.0034 - mae: 0.0410 - rmsle_cust: 0.0035 - val_loss: 0.0084 - val_mae: 0.0647 - val_rmsle_cust: 0.0057\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 1s 216ms/step - loss: 0.0033 - mae: 0.0407 - rmsle_cust: 0.0036 - val_loss: 0.0084 - val_mae: 0.0645 - val_rmsle_cust: 0.0057\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 1s 212ms/step - loss: 0.0032 - mae: 0.0403 - rmsle_cust: 0.0034 - val_loss: 0.0084 - val_mae: 0.0644 - val_rmsle_cust: 0.0057\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 1s 197ms/step - loss: 0.0031 - mae: 0.0400 - rmsle_cust: 0.0034 - val_loss: 0.0084 - val_mae: 0.0643 - val_rmsle_cust: 0.0057\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 1s 202ms/step - loss: 0.0030 - mae: 0.0391 - rmsle_cust: 0.0033 - val_loss: 0.0084 - val_mae: 0.0645 - val_rmsle_cust: 0.0057\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.0030 - mae: 0.0388 - rmsle_cust: 0.0033 - val_loss: 0.0084 - val_mae: 0.0645 - val_rmsle_cust: 0.0057\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 1s 204ms/step - loss: 0.0030 - mae: 0.0389 - rmsle_cust: 0.0033 - val_loss: 0.0084 - val_mae: 0.0644 - val_rmsle_cust: 0.0057\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 1s 210ms/step - loss: 0.0029 - mae: 0.0380 - rmsle_cust: 0.0032 - val_loss: 0.0084 - val_mae: 0.0644 - val_rmsle_cust: 0.0057\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 1s 210ms/step - loss: 0.0029 - mae: 0.0385 - rmsle_cust: 0.0032 - val_loss: 0.0084 - val_mae: 0.0645 - val_rmsle_cust: 0.0057\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 1s 214ms/step - loss: 0.0028 - mae: 0.0376 - rmsle_cust: 0.0030 - val_loss: 0.0084 - val_mae: 0.0646 - val_rmsle_cust: 0.0058\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.0029 - mae: 0.0381 - rmsle_cust: 0.0031 - val_loss: 0.0084 - val_mae: 0.0646 - val_rmsle_cust: 0.0057\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 1s 202ms/step - loss: 0.0027 - mae: 0.0372 - rmsle_cust: 0.0031 - val_loss: 0.0084 - val_mae: 0.0645 - val_rmsle_cust: 0.0057\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 1s 204ms/step - loss: 0.0027 - mae: 0.0370 - rmsle_cust: 0.0030 - val_loss: 0.0084 - val_mae: 0.0645 - val_rmsle_cust: 0.0056\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 1s 205ms/step - loss: 0.0027 - mae: 0.0375 - rmsle_cust: 0.0030 - val_loss: 0.0085 - val_mae: 0.0645 - val_rmsle_cust: 0.0056\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 1s 202ms/step - loss: 0.0027 - mae: 0.0366 - rmsle_cust: 0.0030 - val_loss: 0.0085 - val_mae: 0.0644 - val_rmsle_cust: 0.0056\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 1s 200ms/step - loss: 0.0026 - mae: 0.0366 - rmsle_cust: 0.0029 - val_loss: 0.0086 - val_mae: 0.0644 - val_rmsle_cust: 0.0055\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 1s 208ms/step - loss: 0.0026 - mae: 0.0365 - rmsle_cust: 0.0030 - val_loss: 0.0086 - val_mae: 0.0642 - val_rmsle_cust: 0.0054\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 1s 211ms/step - loss: 0.0026 - mae: 0.0366 - rmsle_cust: 0.0030 - val_loss: 0.0085 - val_mae: 0.0641 - val_rmsle_cust: 0.0054\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 1s 228ms/step - loss: 0.0026 - mae: 0.0360 - rmsle_cust: 0.0029 - val_loss: 0.0085 - val_mae: 0.0639 - val_rmsle_cust: 0.0053\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 1s 214ms/step - loss: 0.0026 - mae: 0.0360 - rmsle_cust: 0.0028 - val_loss: 0.0086 - val_mae: 0.0638 - val_rmsle_cust: 0.0053\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.0025 - mae: 0.0357 - rmsle_cust: 0.0029 - val_loss: 0.0086 - val_mae: 0.0638 - val_rmsle_cust: 0.0053\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 1s 184ms/step - loss: 0.0025 - mae: 0.0355 - rmsle_cust: 0.0028 - val_loss: 0.0086 - val_mae: 0.0640 - val_rmsle_cust: 0.0053\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 0.0024 - mae: 0.0353 - rmsle_cust: 0.0028 - val_loss: 0.0087 - val_mae: 0.0643 - val_rmsle_cust: 0.0054\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.0024 - mae: 0.0349 - rmsle_cust: 0.0028 - val_loss: 0.0086 - val_mae: 0.0643 - val_rmsle_cust: 0.0054\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 1s 198ms/step - loss: 0.0024 - mae: 0.0353 - rmsle_cust: 0.0027 - val_loss: 0.0086 - val_mae: 0.0646 - val_rmsle_cust: 0.0054\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 1s 192ms/step - loss: 0.0024 - mae: 0.0349 - rmsle_cust: 0.0028 - val_loss: 0.0087 - val_mae: 0.0646 - val_rmsle_cust: 0.0054\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 1s 184ms/step - loss: 0.0024 - mae: 0.0350 - rmsle_cust: 0.0027 - val_loss: 0.0087 - val_mae: 0.0648 - val_rmsle_cust: 0.0055\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 1s 210ms/step - loss: 0.0023 - mae: 0.0343 - rmsle_cust: 0.0028 - val_loss: 0.0086 - val_mae: 0.0641 - val_rmsle_cust: 0.0055\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.0022 - mae: 0.0340 - rmsle_cust: 0.0025 - val_loss: 0.0085 - val_mae: 0.0639 - val_rmsle_cust: 0.0054\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 1s 196ms/step - loss: 0.0022 - mae: 0.0340 - rmsle_cust: 0.0027 - val_loss: 0.0086 - val_mae: 0.0636 - val_rmsle_cust: 0.0054\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.0022 - mae: 0.0344 - rmsle_cust: 0.0029 - val_loss: 0.0085 - val_mae: 0.0633 - val_rmsle_cust: 0.0054\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 1s 225ms/step - loss: 0.0021 - mae: 0.0337 - rmsle_cust: 0.0028 - val_loss: 0.0085 - val_mae: 0.0633 - val_rmsle_cust: 0.0053\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.0022 - mae: 0.0340 - rmsle_cust: 0.0029 - val_loss: 0.0086 - val_mae: 0.0635 - val_rmsle_cust: 0.0053\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 0.0022 - mae: 0.0337 - rmsle_cust: 0.0025 - val_loss: 0.0086 - val_mae: 0.0639 - val_rmsle_cust: 0.0054\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 1s 207ms/step - loss: 0.0022 - mae: 0.0335 - rmsle_cust: 0.0026 - val_loss: 0.0086 - val_mae: 0.0639 - val_rmsle_cust: 0.0054\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 1s 208ms/step - loss: 0.0020 - mae: 0.0329 - rmsle_cust: 0.0026 - val_loss: 0.0086 - val_mae: 0.0639 - val_rmsle_cust: 0.0054\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.0022 - mae: 0.0337 - rmsle_cust: 0.0028 - val_loss: 0.0087 - val_mae: 0.0640 - val_rmsle_cust: 0.0054\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.0021 - mae: 0.0330 - rmsle_cust: 0.0027 - val_loss: 0.0088 - val_mae: 0.0642 - val_rmsle_cust: 0.0054\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 0.0021 - mae: 0.0337 - rmsle_cust: 0.0027 - val_loss: 0.0088 - val_mae: 0.0643 - val_rmsle_cust: 0.0054\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 1s 205ms/step - loss: 0.0020 - mae: 0.0325 - rmsle_cust: 0.0025 - val_loss: 0.0088 - val_mae: 0.0642 - val_rmsle_cust: 0.0055\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 1s 197ms/step - loss: 0.0021 - mae: 0.0328 - rmsle_cust: 0.0026 - val_loss: 0.0088 - val_mae: 0.0644 - val_rmsle_cust: 0.0056\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 1s 196ms/step - loss: 0.0019 - mae: 0.0317 - rmsle_cust: 0.0025 - val_loss: 0.0088 - val_mae: 0.0640 - val_rmsle_cust: 0.0056\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 227ms/step - loss: 0.0020 - mae: 0.0323 - rmsle_cust: 0.0026 - val_loss: 0.0087 - val_mae: 0.0639 - val_rmsle_cust: 0.0056\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 1s 205ms/step - loss: 0.0020 - mae: 0.0325 - rmsle_cust: 0.0025 - val_loss: 0.0088 - val_mae: 0.0642 - val_rmsle_cust: 0.0058\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 1s 213ms/step - loss: 0.0019 - mae: 0.0318 - rmsle_cust: 0.0028 - val_loss: 0.0088 - val_mae: 0.0639 - val_rmsle_cust: 0.0057\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 1s 207ms/step - loss: 0.0019 - mae: 0.0317 - rmsle_cust: 0.0024 - val_loss: 0.0087 - val_mae: 0.0636 - val_rmsle_cust: 0.0056\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 1s 217ms/step - loss: 0.0019 - mae: 0.0319 - rmsle_cust: 0.0026 - val_loss: 0.0087 - val_mae: 0.0637 - val_rmsle_cust: 0.0056\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 1s 200ms/step - loss: 0.0020 - mae: 0.0323 - rmsle_cust: 0.0024 - val_loss: 0.0088 - val_mae: 0.0640 - val_rmsle_cust: 0.0055\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 1s 220ms/step - loss: 0.0018 - mae: 0.0308 - rmsle_cust: 0.0025 - val_loss: 0.0088 - val_mae: 0.0640 - val_rmsle_cust: 0.0055\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 1s 211ms/step - loss: 0.0019 - mae: 0.0316 - rmsle_cust: 0.0025 - val_loss: 0.0087 - val_mae: 0.0639 - val_rmsle_cust: 0.0054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263e7178f70>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Fitting\n",
    "\n",
    "BATCH_SIZE = 2500\n",
    "epochs = 100\n",
    "gru_model = get_gru_model()\n",
    "gru_model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_test, dtest.target)\n",
    "          , verbose=1, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_range=np.log(history.losses)\n",
    "sns.distplot(history.losses, hist=False)\n",
    "plt.title('Training Loss')\n",
    "plt.grid()\n",
    "plt.legend('top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 8ms/step\n",
      " RMSLE error for GRU Based Model on Test Data: 0.23153247567428636\n",
      " RMSE error for GRU Based Model on Test Data: 9.011227412966234\n"
     ]
    }
   ],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n",
    "    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n",
    "\n",
    "val_preds = gru_model.predict(X_test)\n",
    "val_preds = target_scaler.inverse_transform(val_preds)\n",
    "val_preds = np.exp(val_preds)+1\n",
    "\n",
    "# mean_absolute_error, mean_squared_log_error.\n",
    "y_true = np.array(dtest.mrp.values)\n",
    "y_pred = val_preds[:,0]\n",
    "v_rmsle = rmsle(y_true, y_pred)\n",
    "v_rmse = mean_squared_error(y_true, y_pred , squared=False)\n",
    "print(\" RMSLE error for GRU Based Model on Test Data: \"+str(v_rmsle))\n",
    "print(\" RMSE error for GRU Based Model on Test Data: \"+str(v_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_category_wide</th>\n",
       "      <th>mrp</th>\n",
       "      <th>clean_description</th>\n",
       "      <th>seq_description</th>\n",
       "      <th>seq_product_name</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>logo to go low rise thong 631581</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>22.00</td>\n",
       "      <td>soft  sheer lace wraps around waist lightweigh...</td>\n",
       "      <td>[18, 72, 1, 1261, 521, 161, 264, 20, 8, 83, 90]</td>\n",
       "      <td>[35, 87, 65, 21, 16, 8, 1980]</td>\n",
       "      <td>-0.468620</td>\n",
       "      <td>28.675802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>lace plunge bra</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>35.00</td>\n",
       "      <td>elegant black plunge bra prettified gorgeous l...</td>\n",
       "      <td>[488, 133, 80, 2, 2973, 238, 1, 711, 109, 324,...</td>\n",
       "      <td>[1, 80, 2]</td>\n",
       "      <td>-0.268490</td>\n",
       "      <td>27.243176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>classic mesh triangle bralette</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>54.00</td>\n",
       "      <td>classic silhouettes airy stretch mesh</td>\n",
       "      <td>[100, 682, 616, 34, 36]</td>\n",
       "      <td>[100, 36, 68, 19]</td>\n",
       "      <td>-0.079174</td>\n",
       "      <td>49.475212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>happy unlined bandeau bra</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26.95</td>\n",
       "      <td>hello  happy bras  happiness feeling like real...</td>\n",
       "      <td>[240, 52, 92, 148, 269, 150, 12, 235, 360, 52,...</td>\n",
       "      <td>[52, 169, 312, 2]</td>\n",
       "      <td>-0.381549</td>\n",
       "      <td>26.561493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>b.provocative contrast-lace bra 951222</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>40.00</td>\n",
       "      <td>flattering sheer nude panels decorated intrica...</td>\n",
       "      <td>[215, 72, 393, 781, 999, 571, 1250, 325, 3311,...</td>\n",
       "      <td>[67, 686, 216, 1, 2, 3892]</td>\n",
       "      <td>-0.210396</td>\n",
       "      <td>40.169598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                product_name  brand_name  product_category_wide    mrp                                  clean_description                                    seq_description               seq_product_name    target  predicted_price\n",
       "3619        logo to go low rise thong 631581           6                      7  22.00  soft  sheer lace wraps around waist lightweigh...    [18, 72, 1, 1261, 521, 161, 264, 20, 8, 83, 90]  [35, 87, 65, 21, 16, 8, 1980] -0.468620        28.675802\n",
       "3444                         lace plunge bra          12                      4  35.00  elegant black plunge bra prettified gorgeous l...  [488, 133, 80, 2, 2973, 238, 1, 711, 109, 324,...                     [1, 80, 2] -0.268490        27.243176\n",
       "2517          classic mesh triangle bralette           6                      3  54.00             classic silhouettes airy stretch mesh                             [100, 682, 616, 34, 36]              [100, 36, 68, 19] -0.079174        49.475212\n",
       "3076               happy unlined bandeau bra           0                      4  26.95  hello  happy bras  happiness feeling like real...  [240, 52, 92, 148, 269, 150, 12, 235, 360, 52,...              [52, 169, 312, 2] -0.381549        26.561493\n",
       "5635  b.provocative contrast-lace bra 951222           1                      4  40.00  flattering sheer nude panels decorated intrica...  [215, 72, 393, 781, 999, 571, 1250, 325, 3311,...     [67, 686, 216, 1, 2, 3892] -0.210396        40.169598"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the price.\n",
    "preds = gru_model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "preds = target_scaler.inverse_transform(preds)\n",
    "preds = np.exp(preds)-1\n",
    "dtest[\"predicted_price\"] = preds\n",
    "dtest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " item_desc (InputLayer)         [(None, 75)]         0           []                               \n",
      "                                                                                                  \n",
      " item_name (InputLayer)         [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " brand_name (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " product_category (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding_57 (Embedding)       (None, 75, 50)       195500      ['item_desc[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_56 (Embedding)       (None, 10, 50)       195500      ['item_name[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_58 (Embedding)       (None, 1, 10)        160         ['brand_name[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_59 (Embedding)       (None, 1, 10)        160         ['product_category[0][0]']       \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 16)           4288        ['embedding_57[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 8)            1888        ['embedding_56[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_28 (Flatten)           (None, 10)           0           ['embedding_58[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_29 (Flatten)           (None, 10)           0           ['embedding_59[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 44)           0           ['lstm_4[0][0]',                 \n",
      "                                                                  'lstm_5[0][0]',                 \n",
      "                                                                  'flatten_28[0][0]',             \n",
      "                                                                  'flatten_29[0][0]']             \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 128)          5760        ['concatenate_18[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 128)          0           ['dense_44[0][0]']               \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 64)           8256        ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 64)           0           ['dense_45[0][0]']               \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 1)            65          ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 411,577\n",
      "Trainable params: 411,577\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_lstm_model():\n",
    "    # Params\n",
    "    dr_r = 0.1\n",
    "    \n",
    "    # Inputs\n",
    "    item_name = Input(shape=[X_train[\"item_name\"].shape[1]], name=\"item_name\")\n",
    "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    product_category = Input(shape=[1], name=\"product_category\")\n",
    "    \n",
    "    # Embeddings Layers\n",
    "    emb_item_name = Embedding(MAX_TEXT, 50)(item_name)\n",
    "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    emb_product_category = Embedding(MAX_CAT, 10)(product_category)\n",
    "    \n",
    "    # RNN Layer\n",
    "    rnn_layer1 = LSTM(16) (emb_item_desc)\n",
    "    rnn_layer2 = LSTM(8) (emb_item_name)\n",
    "    \n",
    "    # Main Layer\n",
    "    main_l = concatenate([\n",
    "        rnn_layer1,\n",
    "        rnn_layer2,\n",
    "        Flatten() (emb_brand_name)\n",
    "        , Flatten() (emb_product_category)\n",
    "    ])\n",
    "    main_l = Dropout(dr_r) (Dense(128) (main_l))\n",
    "    main_l = Dropout(dr_r) (Dense(64) (main_l))\n",
    "    \n",
    "    # Output Layer\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    # Init Model\n",
    "    model = Model([item_name, item_desc, brand_name, product_category], output)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "lstm_model = get_lstm_model()\n",
    "history = LossHistory()\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.2068 - mae: 0.3757 - rmsle_cust: 0.0218 - val_loss: 0.1395 - val_mae: 0.2973 - val_rmsle_cust: 0.0077\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.1465 - mae: 0.3064 - rmsle_cust: 0.0101 - val_loss: 0.0970 - val_mae: 0.2424 - val_rmsle_cust: 0.0077\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.1015 - mae: 0.2480 - rmsle_cust: 0.0101 - val_loss: 0.0700 - val_mae: 0.2061 - val_rmsle_cust: 0.0077\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0720 - mae: 0.2116 - rmsle_cust: 0.0101 - val_loss: 0.0629 - val_mae: 0.2072 - val_rmsle_cust: 0.0077\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0638 - mae: 0.2086 - rmsle_cust: 0.0101 - val_loss: 0.0641 - val_mae: 0.2153 - val_rmsle_cust: 0.0077\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0624 - mae: 0.2093 - rmsle_cust: 0.0101 - val_loss: 0.0545 - val_mae: 0.1963 - val_rmsle_cust: 0.0077\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.0526 - mae: 0.1898 - rmsle_cust: 0.0101 - val_loss: 0.0396 - val_mae: 0.1625 - val_rmsle_cust: 0.0077\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0389 - mae: 0.1586 - rmsle_cust: 0.0101 - val_loss: 0.0302 - val_mae: 0.1364 - val_rmsle_cust: 0.0077\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0305 - mae: 0.1352 - rmsle_cust: 0.0101 - val_loss: 0.0270 - val_mae: 0.1280 - val_rmsle_cust: 0.0078\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0273 - mae: 0.1280 - rmsle_cust: 0.0100 - val_loss: 0.0246 - val_mae: 0.1237 - val_rmsle_cust: 0.0084\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0244 - mae: 0.1217 - rmsle_cust: 0.0100 - val_loss: 0.0205 - val_mae: 0.1113 - val_rmsle_cust: 0.0090\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.0198 - mae: 0.1080 - rmsle_cust: 0.0106 - val_loss: 0.0178 - val_mae: 0.1011 - val_rmsle_cust: 0.0091\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0175 - mae: 0.0985 - rmsle_cust: 0.0106 - val_loss: 0.0184 - val_mae: 0.1011 - val_rmsle_cust: 0.0088\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0184 - mae: 0.1003 - rmsle_cust: 0.0103 - val_loss: 0.0181 - val_mae: 0.1000 - val_rmsle_cust: 0.0086\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0179 - mae: 0.0987 - rmsle_cust: 0.0098 - val_loss: 0.0154 - val_mae: 0.0924 - val_rmsle_cust: 0.0086\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0145 - mae: 0.0885 - rmsle_cust: 0.0097 - val_loss: 0.0137 - val_mae: 0.0887 - val_rmsle_cust: 0.0085\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0123 - mae: 0.0825 - rmsle_cust: 0.0093 - val_loss: 0.0132 - val_mae: 0.0877 - val_rmsle_cust: 0.0078\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 0.0115 - mae: 0.0807 - rmsle_cust: 0.0083 - val_loss: 0.0123 - val_mae: 0.0837 - val_rmsle_cust: 0.0070\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0102 - mae: 0.0741 - rmsle_cust: 0.0074 - val_loss: 0.0112 - val_mae: 0.0778 - val_rmsle_cust: 0.0063\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0089 - mae: 0.0678 - rmsle_cust: 0.0066 - val_loss: 0.0108 - val_mae: 0.0762 - val_rmsle_cust: 0.0062\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0083 - mae: 0.0654 - rmsle_cust: 0.0062 - val_loss: 0.0109 - val_mae: 0.0778 - val_rmsle_cust: 0.0061\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0081 - mae: 0.0660 - rmsle_cust: 0.0061 - val_loss: 0.0106 - val_mae: 0.0769 - val_rmsle_cust: 0.0060\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0076 - mae: 0.0643 - rmsle_cust: 0.0059 - val_loss: 0.0100 - val_mae: 0.0744 - val_rmsle_cust: 0.0060\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0066 - mae: 0.0591 - rmsle_cust: 0.0057 - val_loss: 0.0098 - val_mae: 0.0732 - val_rmsle_cust: 0.0060\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0063 - mae: 0.0584 - rmsle_cust: 0.0057 - val_loss: 0.0098 - val_mae: 0.0730 - val_rmsle_cust: 0.0060\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 1s 331ms/step - loss: 0.0063 - mae: 0.0581 - rmsle_cust: 0.0060 - val_loss: 0.0094 - val_mae: 0.0712 - val_rmsle_cust: 0.0060\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0058 - mae: 0.0552 - rmsle_cust: 0.0060 - val_loss: 0.0090 - val_mae: 0.0703 - val_rmsle_cust: 0.0059\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0056 - mae: 0.0541 - rmsle_cust: 0.0059 - val_loss: 0.0089 - val_mae: 0.0698 - val_rmsle_cust: 0.0058\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0054 - mae: 0.0540 - rmsle_cust: 0.0057 - val_loss: 0.0087 - val_mae: 0.0682 - val_rmsle_cust: 0.0057\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 0.0051 - mae: 0.0525 - rmsle_cust: 0.0056 - val_loss: 0.0085 - val_mae: 0.0665 - val_rmsle_cust: 0.0056\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0049 - mae: 0.0509 - rmsle_cust: 0.0054 - val_loss: 0.0084 - val_mae: 0.0662 - val_rmsle_cust: 0.0055\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0046 - mae: 0.0491 - rmsle_cust: 0.0051 - val_loss: 0.0083 - val_mae: 0.0654 - val_rmsle_cust: 0.0055\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0045 - mae: 0.0490 - rmsle_cust: 0.0049 - val_loss: 0.0081 - val_mae: 0.0641 - val_rmsle_cust: 0.0054\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0043 - mae: 0.0468 - rmsle_cust: 0.0044 - val_loss: 0.0079 - val_mae: 0.0632 - val_rmsle_cust: 0.0054\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 1s 326ms/step - loss: 0.0041 - mae: 0.0461 - rmsle_cust: 0.0043 - val_loss: 0.0078 - val_mae: 0.0627 - val_rmsle_cust: 0.0054\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0038 - mae: 0.0450 - rmsle_cust: 0.0042 - val_loss: 0.0077 - val_mae: 0.0621 - val_rmsle_cust: 0.0053\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 1s 325ms/step - loss: 0.0038 - mae: 0.0447 - rmsle_cust: 0.0040 - val_loss: 0.0076 - val_mae: 0.0615 - val_rmsle_cust: 0.0053\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0037 - mae: 0.0442 - rmsle_cust: 0.0039 - val_loss: 0.0076 - val_mae: 0.0610 - val_rmsle_cust: 0.0053\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0035 - mae: 0.0431 - rmsle_cust: 0.0038 - val_loss: 0.0074 - val_mae: 0.0606 - val_rmsle_cust: 0.0053\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0035 - mae: 0.0426 - rmsle_cust: 0.0039 - val_loss: 0.0074 - val_mae: 0.0603 - val_rmsle_cust: 0.0052\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0034 - mae: 0.0423 - rmsle_cust: 0.0037 - val_loss: 0.0073 - val_mae: 0.0600 - val_rmsle_cust: 0.0052\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0033 - mae: 0.0419 - rmsle_cust: 0.0037 - val_loss: 0.0073 - val_mae: 0.0598 - val_rmsle_cust: 0.0051\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0033 - mae: 0.0410 - rmsle_cust: 0.0037 - val_loss: 0.0073 - val_mae: 0.0597 - val_rmsle_cust: 0.0050\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 0.0030 - mae: 0.0397 - rmsle_cust: 0.0033 - val_loss: 0.0073 - val_mae: 0.0595 - val_rmsle_cust: 0.0050\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0030 - mae: 0.0394 - rmsle_cust: 0.0033 - val_loss: 0.0073 - val_mae: 0.0594 - val_rmsle_cust: 0.0049\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0030 - mae: 0.0396 - rmsle_cust: 0.0033 - val_loss: 0.0072 - val_mae: 0.0596 - val_rmsle_cust: 0.0049\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 318ms/step - loss: 0.0030 - mae: 0.0398 - rmsle_cust: 0.0033 - val_loss: 0.0072 - val_mae: 0.0593 - val_rmsle_cust: 0.0049\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 0.0029 - mae: 0.0394 - rmsle_cust: 0.0032 - val_loss: 0.0072 - val_mae: 0.0590 - val_rmsle_cust: 0.0049\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0027 - mae: 0.0375 - rmsle_cust: 0.0031 - val_loss: 0.0071 - val_mae: 0.0588 - val_rmsle_cust: 0.0049\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0027 - mae: 0.0379 - rmsle_cust: 0.0031 - val_loss: 0.0071 - val_mae: 0.0588 - val_rmsle_cust: 0.0048\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 1s 331ms/step - loss: 0.0027 - mae: 0.0375 - rmsle_cust: 0.0031 - val_loss: 0.0071 - val_mae: 0.0587 - val_rmsle_cust: 0.0048\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0027 - mae: 0.0375 - rmsle_cust: 0.0031 - val_loss: 0.0070 - val_mae: 0.0587 - val_rmsle_cust: 0.0048\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 1s 313ms/step - loss: 0.0026 - mae: 0.0362 - rmsle_cust: 0.0030 - val_loss: 0.0071 - val_mae: 0.0587 - val_rmsle_cust: 0.0048\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0025 - mae: 0.0359 - rmsle_cust: 0.0030 - val_loss: 0.0070 - val_mae: 0.0587 - val_rmsle_cust: 0.0048\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 1s 331ms/step - loss: 0.0025 - mae: 0.0362 - rmsle_cust: 0.0030 - val_loss: 0.0071 - val_mae: 0.0586 - val_rmsle_cust: 0.0048\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.0025 - mae: 0.0362 - rmsle_cust: 0.0029 - val_loss: 0.0071 - val_mae: 0.0585 - val_rmsle_cust: 0.0048\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0024 - mae: 0.0352 - rmsle_cust: 0.0029 - val_loss: 0.0070 - val_mae: 0.0582 - val_rmsle_cust: 0.0048\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.0024 - mae: 0.0354 - rmsle_cust: 0.0028 - val_loss: 0.0070 - val_mae: 0.0582 - val_rmsle_cust: 0.0048\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 1s 330ms/step - loss: 0.0025 - mae: 0.0362 - rmsle_cust: 0.0027 - val_loss: 0.0069 - val_mae: 0.0583 - val_rmsle_cust: 0.0049\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0023 - mae: 0.0349 - rmsle_cust: 0.0027 - val_loss: 0.0069 - val_mae: 0.0582 - val_rmsle_cust: 0.0050\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0024 - mae: 0.0354 - rmsle_cust: 0.0028 - val_loss: 0.0069 - val_mae: 0.0580 - val_rmsle_cust: 0.0050\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 1s 327ms/step - loss: 0.0024 - mae: 0.0349 - rmsle_cust: 0.0025 - val_loss: 0.0069 - val_mae: 0.0579 - val_rmsle_cust: 0.0050\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0023 - mae: 0.0346 - rmsle_cust: 0.0025 - val_loss: 0.0069 - val_mae: 0.0579 - val_rmsle_cust: 0.0049\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 1s 339ms/step - loss: 0.0022 - mae: 0.0337 - rmsle_cust: 0.0026 - val_loss: 0.0069 - val_mae: 0.0577 - val_rmsle_cust: 0.0049\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 0.0022 - mae: 0.0333 - rmsle_cust: 0.0026 - val_loss: 0.0070 - val_mae: 0.0577 - val_rmsle_cust: 0.0049\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 1s 323ms/step - loss: 0.0022 - mae: 0.0339 - rmsle_cust: 0.0026 - val_loss: 0.0070 - val_mae: 0.0578 - val_rmsle_cust: 0.0048\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0021 - mae: 0.0336 - rmsle_cust: 0.0025 - val_loss: 0.0070 - val_mae: 0.0580 - val_rmsle_cust: 0.0048\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0021 - mae: 0.0331 - rmsle_cust: 0.0025 - val_loss: 0.0070 - val_mae: 0.0582 - val_rmsle_cust: 0.0048\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 1s 272ms/step - loss: 0.0022 - mae: 0.0335 - rmsle_cust: 0.0025 - val_loss: 0.0070 - val_mae: 0.0580 - val_rmsle_cust: 0.0047\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0022 - mae: 0.0337 - rmsle_cust: 0.0026 - val_loss: 0.0070 - val_mae: 0.0578 - val_rmsle_cust: 0.0047\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0021 - mae: 0.0331 - rmsle_cust: 0.0027 - val_loss: 0.0070 - val_mae: 0.0576 - val_rmsle_cust: 0.0046\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0021 - mae: 0.0333 - rmsle_cust: 0.0026 - val_loss: 0.0070 - val_mae: 0.0574 - val_rmsle_cust: 0.0046\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 1s 268ms/step - loss: 0.0021 - mae: 0.0329 - rmsle_cust: 0.0025 - val_loss: 0.0070 - val_mae: 0.0572 - val_rmsle_cust: 0.0047\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 1s 267ms/step - loss: 0.0021 - mae: 0.0325 - rmsle_cust: 0.0025 - val_loss: 0.0070 - val_mae: 0.0572 - val_rmsle_cust: 0.0047\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0020 - mae: 0.0321 - rmsle_cust: 0.0024 - val_loss: 0.0069 - val_mae: 0.0573 - val_rmsle_cust: 0.0048\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0019 - mae: 0.0320 - rmsle_cust: 0.0024 - val_loss: 0.0070 - val_mae: 0.0573 - val_rmsle_cust: 0.0048\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0020 - mae: 0.0318 - rmsle_cust: 0.0025 - val_loss: 0.0070 - val_mae: 0.0574 - val_rmsle_cust: 0.0048\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 1s 266ms/step - loss: 0.0019 - mae: 0.0314 - rmsle_cust: 0.0024 - val_loss: 0.0070 - val_mae: 0.0574 - val_rmsle_cust: 0.0048\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0019 - mae: 0.0315 - rmsle_cust: 0.0023 - val_loss: 0.0070 - val_mae: 0.0573 - val_rmsle_cust: 0.0048\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0019 - mae: 0.0313 - rmsle_cust: 0.0024 - val_loss: 0.0070 - val_mae: 0.0572 - val_rmsle_cust: 0.0048\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0019 - mae: 0.0314 - rmsle_cust: 0.0024 - val_loss: 0.0069 - val_mae: 0.0570 - val_rmsle_cust: 0.0048\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0019 - mae: 0.0319 - rmsle_cust: 0.0026 - val_loss: 0.0069 - val_mae: 0.0567 - val_rmsle_cust: 0.0047\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 1s 263ms/step - loss: 0.0018 - mae: 0.0306 - rmsle_cust: 0.0024 - val_loss: 0.0069 - val_mae: 0.0564 - val_rmsle_cust: 0.0047\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0020 - mae: 0.0315 - rmsle_cust: 0.0023 - val_loss: 0.0068 - val_mae: 0.0565 - val_rmsle_cust: 0.0048\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0019 - mae: 0.0313 - rmsle_cust: 0.0023 - val_loss: 0.0068 - val_mae: 0.0567 - val_rmsle_cust: 0.0048\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0019 - mae: 0.0312 - rmsle_cust: 0.0023 - val_loss: 0.0069 - val_mae: 0.0571 - val_rmsle_cust: 0.0049\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.0018 - mae: 0.0306 - rmsle_cust: 0.0024 - val_loss: 0.0069 - val_mae: 0.0571 - val_rmsle_cust: 0.0048\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0019 - mae: 0.0310 - rmsle_cust: 0.0024 - val_loss: 0.0069 - val_mae: 0.0571 - val_rmsle_cust: 0.0048\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 0.0018 - mae: 0.0303 - rmsle_cust: 0.0024 - val_loss: 0.0070 - val_mae: 0.0571 - val_rmsle_cust: 0.0048\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0018 - mae: 0.0299 - rmsle_cust: 0.0023 - val_loss: 0.0070 - val_mae: 0.0572 - val_rmsle_cust: 0.0048\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0018 - mae: 0.0308 - rmsle_cust: 0.0024 - val_loss: 0.0071 - val_mae: 0.0571 - val_rmsle_cust: 0.0048\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0018 - mae: 0.0308 - rmsle_cust: 0.0022 - val_loss: 0.0070 - val_mae: 0.0573 - val_rmsle_cust: 0.0049\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 287ms/step - loss: 0.0017 - mae: 0.0301 - rmsle_cust: 0.0024 - val_loss: 0.0071 - val_mae: 0.0570 - val_rmsle_cust: 0.0049\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 1s 283ms/step - loss: 0.0018 - mae: 0.0303 - rmsle_cust: 0.0024 - val_loss: 0.0071 - val_mae: 0.0571 - val_rmsle_cust: 0.0049\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 0.0017 - mae: 0.0293 - rmsle_cust: 0.0023 - val_loss: 0.0070 - val_mae: 0.0568 - val_rmsle_cust: 0.0048\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0017 - mae: 0.0297 - rmsle_cust: 0.0022 - val_loss: 0.0070 - val_mae: 0.0570 - val_rmsle_cust: 0.0048\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.0017 - mae: 0.0301 - rmsle_cust: 0.0023 - val_loss: 0.0071 - val_mae: 0.0570 - val_rmsle_cust: 0.0047\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0018 - mae: 0.0306 - rmsle_cust: 0.0023 - val_loss: 0.0071 - val_mae: 0.0571 - val_rmsle_cust: 0.0047\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0016 - mae: 0.0291 - rmsle_cust: 0.0024 - val_loss: 0.0071 - val_mae: 0.0571 - val_rmsle_cust: 0.0046\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 0.0017 - mae: 0.0294 - rmsle_cust: 0.0022 - val_loss: 0.0071 - val_mae: 0.0570 - val_rmsle_cust: 0.0045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x263e7a34d90>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = get_lstm_model()\n",
    "lstm_model.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n",
    "          , validation_data=(X_test, dtest.target)\n",
    "          , verbose=1, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_range=np.log(history.losses)\n",
    "sns.distplot(history.losses, hist=False)\n",
    "plt.title('Training Loss')\n",
    "plt.grid()\n",
    "plt.legend('top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 7ms/step\n",
      " RMSLE error for LSTM Based Model on Test Data: 0.2119349472811347\n",
      " RMSE error for LSTM Based Model on Test Data: 7.936809359813508\n"
     ]
    }
   ],
   "source": [
    "val_preds = lstm_model.predict(X_test)\n",
    "val_preds = target_scaler.inverse_transform(val_preds)\n",
    "val_preds = np.exp(val_preds)+1\n",
    "\n",
    "# mean_absolute_error, mean_squared_log_error.\n",
    "y_true = np.array(dtest.mrp.values)\n",
    "y_pred = val_preds[:,0]\n",
    "v_rmsle = rmsle(y_true, y_pred)\n",
    "v_rmse = mean_squared_error(y_true, y_pred , squared=False)\n",
    "print(\" RMSLE error for LSTM Based Model on Test Data: \"+str(v_rmsle))\n",
    "print(\" RMSE error for LSTM Based Model on Test Data: \"+str(v_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_category_wide</th>\n",
       "      <th>mrp</th>\n",
       "      <th>clean_description</th>\n",
       "      <th>seq_description</th>\n",
       "      <th>seq_product_name</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>logo to go low rise thong 631581</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>22.00</td>\n",
       "      <td>soft  sheer lace wraps around waist lightweigh...</td>\n",
       "      <td>[18, 72, 1, 1261, 521, 161, 264, 20, 8, 83, 90]</td>\n",
       "      <td>[35, 87, 65, 21, 16, 8, 1980]</td>\n",
       "      <td>-0.468620</td>\n",
       "      <td>26.587652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>lace plunge bra</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>35.00</td>\n",
       "      <td>elegant black plunge bra prettified gorgeous l...</td>\n",
       "      <td>[488, 133, 80, 2, 2973, 238, 1, 711, 109, 324,...</td>\n",
       "      <td>[1, 80, 2]</td>\n",
       "      <td>-0.268490</td>\n",
       "      <td>25.817434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>classic mesh triangle bralette</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>54.00</td>\n",
       "      <td>classic silhouettes airy stretch mesh</td>\n",
       "      <td>[100, 682, 616, 34, 36]</td>\n",
       "      <td>[100, 36, 68, 19]</td>\n",
       "      <td>-0.079174</td>\n",
       "      <td>47.979275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>happy unlined bandeau bra</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26.95</td>\n",
       "      <td>hello  happy bras  happiness feeling like real...</td>\n",
       "      <td>[240, 52, 92, 148, 269, 150, 12, 235, 360, 52,...</td>\n",
       "      <td>[52, 169, 312, 2]</td>\n",
       "      <td>-0.381549</td>\n",
       "      <td>27.209633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>b.provocative contrast-lace bra 951222</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>40.00</td>\n",
       "      <td>flattering sheer nude panels decorated intrica...</td>\n",
       "      <td>[215, 72, 393, 781, 999, 571, 1250, 325, 3311,...</td>\n",
       "      <td>[67, 686, 216, 1, 2, 3892]</td>\n",
       "      <td>-0.210396</td>\n",
       "      <td>38.513603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                product_name  brand_name  product_category_wide    mrp                                  clean_description                                    seq_description               seq_product_name    target  predicted_price\n",
       "3619        logo to go low rise thong 631581           6                      7  22.00  soft  sheer lace wraps around waist lightweigh...    [18, 72, 1, 1261, 521, 161, 264, 20, 8, 83, 90]  [35, 87, 65, 21, 16, 8, 1980] -0.468620        26.587652\n",
       "3444                         lace plunge bra          12                      4  35.00  elegant black plunge bra prettified gorgeous l...  [488, 133, 80, 2, 2973, 238, 1, 711, 109, 324,...                     [1, 80, 2] -0.268490        25.817434\n",
       "2517          classic mesh triangle bralette           6                      3  54.00             classic silhouettes airy stretch mesh                             [100, 682, 616, 34, 36]              [100, 36, 68, 19] -0.079174        47.979275\n",
       "3076               happy unlined bandeau bra           0                      4  26.95  hello  happy bras  happiness feeling like real...  [240, 52, 92, 148, 269, 150, 12, 235, 360, 52,...              [52, 169, 312, 2] -0.381549        27.209633\n",
       "5635  b.provocative contrast-lace bra 951222           1                      4  40.00  flattering sheer nude panels decorated intrica...  [215, 72, 393, 781, 999, 571, 1250, 325, 3311,...     [67, 686, 216, 1, 2, 3892] -0.210396        38.513603"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the price.\n",
    "preds = lstm_model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "preds = target_scaler.inverse_transform(preds)\n",
    "preds = np.exp(preds)-1\n",
    "dtest[\"predicted_price\"] = preds\n",
    "dtest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " item_name (InputLayer)         [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " item_desc (InputLayer)         [(None, 75)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_80 (Embedding)       (None, 10, 50)       195500      ['item_name[0][0]']              \n",
      "                                                                                                  \n",
      " embedding_81 (Embedding)       (None, 75, 50)       195500      ['item_desc[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 10, 50)       2550        ['embedding_80[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 10, 50)       5050        ['embedding_80[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 10, 50)       7550        ['embedding_80[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 75, 50)       2550        ['embedding_81[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 75, 50)       5050        ['embedding_81[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 75, 50)       7550        ['embedding_81[0][0]']           \n",
      "                                                                                                  \n",
      " brand_name (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " product_category (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " global_max_pooling1d_36 (Globa  (None, 50)          0           ['conv1d_36[0][0]']              \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " global_max_pooling1d_38 (Globa  (None, 50)          0           ['conv1d_38[0][0]']              \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " global_max_pooling1d_40 (Globa  (None, 50)          0           ['conv1d_40[0][0]']              \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " global_max_pooling1d_37 (Globa  (None, 50)          0           ['conv1d_37[0][0]']              \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " global_max_pooling1d_39 (Globa  (None, 50)          0           ['conv1d_39[0][0]']              \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " global_max_pooling1d_41 (Globa  (None, 50)          0           ['conv1d_41[0][0]']              \n",
      " lMaxPooling1D)                                                                                   \n",
      "                                                                                                  \n",
      " embedding_82 (Embedding)       (None, 1, 10)        160         ['brand_name[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_83 (Embedding)       (None, 1, 10)        160         ['product_category[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 150)          0           ['global_max_pooling1d_36[0][0]',\n",
      "                                                                  'global_max_pooling1d_38[0][0]',\n",
      "                                                                  'global_max_pooling1d_40[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 150)          0           ['global_max_pooling1d_37[0][0]',\n",
      "                                                                  'global_max_pooling1d_39[0][0]',\n",
      "                                                                  'global_max_pooling1d_41[0][0]']\n",
      "                                                                                                  \n",
      " flatten_40 (Flatten)           (None, 10)           0           ['embedding_82[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_41 (Flatten)           (None, 10)           0           ['embedding_83[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 320)          0           ['concatenate_32[0][0]',         \n",
      "                                                                  'concatenate_33[0][0]',         \n",
      "                                                                  'flatten_40[0][0]',             \n",
      "                                                                  'flatten_41[0][0]']             \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 256)          82176       ['concatenate_34[0][0]']         \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 256)          0           ['dense_66[0][0]']               \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 128)          32896       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 128)          0           ['dense_67[0][0]']               \n",
      "                                                                                                  \n",
      " dense_68 (Dense)               (None, 64)           8256        ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 64)           0           ['dense_68[0][0]']               \n",
      "                                                                                                  \n",
      " dense_69 (Dense)               (None, 1)            65          ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 545,013\n",
      "Trainable params: 545,013\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def cnn_model(lr=0.001, decay=0.0):\n",
    "\n",
    "    # Inputs\n",
    "    item_name = Input(shape=[X_train[\"item_name\"].shape[1]], name=\"item_name\")\n",
    "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    product_category = Input(shape=[1], name=\"product_category\")\n",
    "\n",
    "    # Embeddings layers\n",
    "    emb_item_name = Embedding(MAX_TEXT, 50)(item_name)\n",
    "    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    emb_product_category = Embedding(MAX_CAT, 10)(product_category)\n",
    "\n",
    "    convs1 = []\n",
    "    convs2 = []\n",
    "    \n",
    "    for filter_length in [1,2,3]:\n",
    "        cnn_layer1 = Conv1D(filters=50, kernel_size=filter_length, padding='same', activation='relu', strides=1) (emb_item_name)\n",
    "        cnn_layer2 = Conv1D(filters=50, kernel_size=filter_length, padding='same', activation='relu', strides=1) (emb_item_desc)\n",
    "        \n",
    "        maxpool1 = GlobalMaxPooling1D() (cnn_layer1)\n",
    "        maxpool2 = GlobalMaxPooling1D() (cnn_layer2)\n",
    "        \n",
    "        convs1.append(maxpool1)\n",
    "        convs2.append(maxpool2)\n",
    "\n",
    "    convs1 = concatenate(convs1)\n",
    "    convs2 = concatenate(convs2)\n",
    "    \n",
    "    # main layers\n",
    "    main_l = concatenate([\n",
    "        convs1,\n",
    "        convs2,\n",
    "        Flatten() (emb_brand_name), \n",
    "        Flatten() (emb_product_category)\n",
    "    ])\n",
    "\n",
    "    main_l = Dense(256)(main_l)\n",
    "    main_l = Activation('elu')(main_l)\n",
    "\n",
    "    main_l = Dense(128)(main_l)\n",
    "    main_l = Activation('elu')(main_l)\n",
    "\n",
    "    main_l = Dense(64)(main_l)\n",
    "    main_l = Activation('elu')(main_l)\n",
    "\n",
    "    # the output layer.\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "\n",
    "    model = Model([item_name, item_desc, brand_name, product_category], output)\n",
    "\n",
    "#     optimizer = Adam(lr=lr, decay=decay)\n",
    "#     model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n",
    "\n",
    "    return model\n",
    "\n",
    "cnn = cnn_model()\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CNN model to training data...\n",
      "Epoch 1/50\n",
      "2/2 - 3s - loss: 0.2147 - mae: 0.3897 - rmsle_cust: 0.0471 - val_loss: 0.1553 - val_mae: 0.3372 - val_rmsle_cust: 0.0077 - 3s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "2/2 - 1s - loss: 0.1456 - mae: 0.3207 - rmsle_cust: 0.0101 - val_loss: 0.0567 - val_mae: 0.1980 - val_rmsle_cust: 0.0077 - 1s/epoch - 673ms/step\n",
      "Epoch 3/50\n",
      "2/2 - 2s - loss: 0.0614 - mae: 0.2016 - rmsle_cust: 0.0101 - val_loss: 0.0776 - val_mae: 0.2217 - val_rmsle_cust: 0.0077 - 2s/epoch - 752ms/step\n",
      "Epoch 4/50\n",
      "2/2 - 1s - loss: 0.0815 - mae: 0.2292 - rmsle_cust: 0.0101 - val_loss: 0.0617 - val_mae: 0.1971 - val_rmsle_cust: 0.0077 - 1s/epoch - 707ms/step\n",
      "Epoch 5/50\n",
      "2/2 - 2s - loss: 0.0612 - mae: 0.1965 - rmsle_cust: 0.0101 - val_loss: 0.0375 - val_mae: 0.1542 - val_rmsle_cust: 0.0077 - 2s/epoch - 752ms/step\n",
      "Epoch 6/50\n",
      "2/2 - 1s - loss: 0.0379 - mae: 0.1533 - rmsle_cust: 0.0101 - val_loss: 0.0422 - val_mae: 0.1694 - val_rmsle_cust: 0.0077 - 1s/epoch - 749ms/step\n",
      "Epoch 7/50\n",
      "2/2 - 1s - loss: 0.0419 - mae: 0.1633 - rmsle_cust: 0.0101 - val_loss: 0.0390 - val_mae: 0.1633 - val_rmsle_cust: 0.0077 - 1s/epoch - 692ms/step\n",
      "Epoch 8/50\n",
      "2/2 - 1s - loss: 0.0364 - mae: 0.1513 - rmsle_cust: 0.0101 - val_loss: 0.0252 - val_mae: 0.1204 - val_rmsle_cust: 0.0077 - 1s/epoch - 739ms/step\n",
      "Epoch 9/50\n",
      "2/2 - 1s - loss: 0.0229 - mae: 0.1112 - rmsle_cust: 0.0101 - val_loss: 0.0247 - val_mae: 0.1194 - val_rmsle_cust: 0.0076 - 1s/epoch - 724ms/step\n",
      "Epoch 10/50\n",
      "2/2 - 1s - loss: 0.0224 - mae: 0.1148 - rmsle_cust: 0.0098 - val_loss: 0.0255 - val_mae: 0.1260 - val_rmsle_cust: 0.0078 - 1s/epoch - 714ms/step\n",
      "Epoch 11/50\n",
      "2/2 - 1s - loss: 0.0217 - mae: 0.1170 - rmsle_cust: 0.0092 - val_loss: 0.0188 - val_mae: 0.1058 - val_rmsle_cust: 0.0078 - 1s/epoch - 735ms/step\n",
      "Epoch 12/50\n",
      "2/2 - 1s - loss: 0.0148 - mae: 0.0931 - rmsle_cust: 0.0090 - val_loss: 0.0172 - val_mae: 0.0988 - val_rmsle_cust: 0.0077 - 1s/epoch - 742ms/step\n",
      "Epoch 13/50\n",
      "2/2 - 1s - loss: 0.0144 - mae: 0.0871 - rmsle_cust: 0.0090 - val_loss: 0.0184 - val_mae: 0.1026 - val_rmsle_cust: 0.0077 - 1s/epoch - 704ms/step\n",
      "Epoch 14/50\n",
      "2/2 - 2s - loss: 0.0150 - mae: 0.0889 - rmsle_cust: 0.0086 - val_loss: 0.0142 - val_mae: 0.0889 - val_rmsle_cust: 0.0076 - 2s/epoch - 800ms/step\n",
      "Epoch 15/50\n",
      "2/2 - 1s - loss: 0.0102 - mae: 0.0730 - rmsle_cust: 0.0079 - val_loss: 0.0145 - val_mae: 0.0911 - val_rmsle_cust: 0.0075 - 1s/epoch - 728ms/step\n",
      "Epoch 16/50\n",
      "2/2 - 2s - loss: 0.0096 - mae: 0.0753 - rmsle_cust: 0.0082 - val_loss: 0.0146 - val_mae: 0.0912 - val_rmsle_cust: 0.0072 - 2s/epoch - 791ms/step\n",
      "Epoch 17/50\n",
      "2/2 - 2s - loss: 0.0090 - mae: 0.0729 - rmsle_cust: 0.0079 - val_loss: 0.0116 - val_mae: 0.0774 - val_rmsle_cust: 0.0066 - 2s/epoch - 759ms/step\n",
      "Epoch 18/50\n",
      "2/2 - 2s - loss: 0.0063 - mae: 0.0541 - rmsle_cust: 0.0066 - val_loss: 0.0115 - val_mae: 0.0796 - val_rmsle_cust: 0.0068 - 2s/epoch - 802ms/step\n",
      "Epoch 19/50\n",
      "2/2 - 2s - loss: 0.0064 - mae: 0.0571 - rmsle_cust: 0.0062 - val_loss: 0.0114 - val_mae: 0.0801 - val_rmsle_cust: 0.0066 - 2s/epoch - 779ms/step\n",
      "Epoch 20/50\n",
      "2/2 - 2s - loss: 0.0060 - mae: 0.0559 - rmsle_cust: 0.0058 - val_loss: 0.0105 - val_mae: 0.0740 - val_rmsle_cust: 0.0060 - 2s/epoch - 802ms/step\n",
      "Epoch 21/50\n",
      "2/2 - 2s - loss: 0.0047 - mae: 0.0478 - rmsle_cust: 0.0056 - val_loss: 0.0111 - val_mae: 0.0753 - val_rmsle_cust: 0.0055 - 2s/epoch - 791ms/step\n",
      "Epoch 22/50\n",
      "2/2 - 2s - loss: 0.0049 - mae: 0.0500 - rmsle_cust: 0.0057 - val_loss: 0.0104 - val_mae: 0.0720 - val_rmsle_cust: 0.0053 - 2s/epoch - 780ms/step\n",
      "Epoch 23/50\n",
      "2/2 - 2s - loss: 0.0041 - mae: 0.0440 - rmsle_cust: 0.0055 - val_loss: 0.0095 - val_mae: 0.0687 - val_rmsle_cust: 0.0052 - 2s/epoch - 894ms/step\n",
      "Epoch 24/50\n",
      "2/2 - 2s - loss: 0.0035 - mae: 0.0410 - rmsle_cust: 0.0049 - val_loss: 0.0094 - val_mae: 0.0690 - val_rmsle_cust: 0.0051 - 2s/epoch - 867ms/step\n",
      "Epoch 25/50\n",
      "2/2 - 2s - loss: 0.0035 - mae: 0.0422 - rmsle_cust: 0.0048 - val_loss: 0.0090 - val_mae: 0.0653 - val_rmsle_cust: 0.0048 - 2s/epoch - 756ms/step\n",
      "Epoch 26/50\n",
      "2/2 - 2s - loss: 0.0028 - mae: 0.0361 - rmsle_cust: 0.0050 - val_loss: 0.0093 - val_mae: 0.0668 - val_rmsle_cust: 0.0047 - 2s/epoch - 876ms/step\n",
      "Epoch 27/50\n",
      "2/2 - 2s - loss: 0.0028 - mae: 0.0368 - rmsle_cust: 0.0052 - val_loss: 0.0090 - val_mae: 0.0645 - val_rmsle_cust: 0.0046 - 2s/epoch - 887ms/step\n",
      "Epoch 28/50\n",
      "2/2 - 2s - loss: 0.0024 - mae: 0.0329 - rmsle_cust: 0.0045 - val_loss: 0.0085 - val_mae: 0.0627 - val_rmsle_cust: 0.0047 - 2s/epoch - 847ms/step\n",
      "Epoch 29/50\n",
      "2/2 - 2s - loss: 0.0021 - mae: 0.0310 - rmsle_cust: 0.0038 - val_loss: 0.0085 - val_mae: 0.0628 - val_rmsle_cust: 0.0048 - 2s/epoch - 855ms/step\n",
      "Epoch 30/50\n",
      "2/2 - 2s - loss: 0.0020 - mae: 0.0299 - rmsle_cust: 0.0035 - val_loss: 0.0085 - val_mae: 0.0615 - val_rmsle_cust: 0.0047 - 2s/epoch - 862ms/step\n",
      "Epoch 31/50\n",
      "2/2 - 2s - loss: 0.0017 - mae: 0.0269 - rmsle_cust: 0.0033 - val_loss: 0.0087 - val_mae: 0.0626 - val_rmsle_cust: 0.0045 - 2s/epoch - 852ms/step\n",
      "Epoch 32/50\n",
      "2/2 - 2s - loss: 0.0017 - mae: 0.0276 - rmsle_cust: 0.0032 - val_loss: 0.0084 - val_mae: 0.0606 - val_rmsle_cust: 0.0046 - 2s/epoch - 1s/step\n",
      "Epoch 33/50\n",
      "2/2 - 2s - loss: 0.0015 - mae: 0.0247 - rmsle_cust: 0.0030 - val_loss: 0.0081 - val_mae: 0.0600 - val_rmsle_cust: 0.0047 - 2s/epoch - 820ms/step\n",
      "Epoch 34/50\n",
      "2/2 - 2s - loss: 0.0014 - mae: 0.0242 - rmsle_cust: 0.0028 - val_loss: 0.0080 - val_mae: 0.0589 - val_rmsle_cust: 0.0045 - 2s/epoch - 985ms/step\n",
      "Epoch 35/50\n",
      "2/2 - 2s - loss: 0.0013 - mae: 0.0224 - rmsle_cust: 0.0027 - val_loss: 0.0080 - val_mae: 0.0583 - val_rmsle_cust: 0.0042 - 2s/epoch - 971ms/step\n",
      "Epoch 36/50\n",
      "2/2 - 2s - loss: 0.0012 - mae: 0.0215 - rmsle_cust: 0.0027 - val_loss: 0.0079 - val_mae: 0.0578 - val_rmsle_cust: 0.0041 - 2s/epoch - 896ms/step\n",
      "Epoch 37/50\n",
      "2/2 - 2s - loss: 0.0011 - mae: 0.0205 - rmsle_cust: 0.0025 - val_loss: 0.0077 - val_mae: 0.0571 - val_rmsle_cust: 0.0041 - 2s/epoch - 986ms/step\n",
      "Epoch 38/50\n",
      "2/2 - 2s - loss: 0.0010 - mae: 0.0196 - rmsle_cust: 0.0023 - val_loss: 0.0077 - val_mae: 0.0568 - val_rmsle_cust: 0.0041 - 2s/epoch - 1s/step\n",
      "Epoch 39/50\n",
      "2/2 - 2s - loss: 9.4209e-04 - mae: 0.0189 - rmsle_cust: 0.0022 - val_loss: 0.0078 - val_mae: 0.0564 - val_rmsle_cust: 0.0040 - 2s/epoch - 945ms/step\n",
      "Epoch 40/50\n",
      "2/2 - 2s - loss: 8.7110e-04 - mae: 0.0177 - rmsle_cust: 0.0022 - val_loss: 0.0078 - val_mae: 0.0564 - val_rmsle_cust: 0.0040 - 2s/epoch - 1s/step\n",
      "Epoch 41/50\n",
      "2/2 - 2s - loss: 8.1721e-04 - mae: 0.0171 - rmsle_cust: 0.0021 - val_loss: 0.0077 - val_mae: 0.0559 - val_rmsle_cust: 0.0040 - 2s/epoch - 1s/step\n",
      "Epoch 42/50\n",
      "2/2 - 2s - loss: 7.6404e-04 - mae: 0.0164 - rmsle_cust: 0.0020 - val_loss: 0.0076 - val_mae: 0.0556 - val_rmsle_cust: 0.0040 - 2s/epoch - 1s/step\n",
      "Epoch 43/50\n",
      "2/2 - 2s - loss: 7.1701e-04 - mae: 0.0159 - rmsle_cust: 0.0019 - val_loss: 0.0076 - val_mae: 0.0554 - val_rmsle_cust: 0.0040 - 2s/epoch - 1s/step\n",
      "Epoch 44/50\n",
      "2/2 - 2s - loss: 6.7086e-04 - mae: 0.0150 - rmsle_cust: 0.0018 - val_loss: 0.0076 - val_mae: 0.0552 - val_rmsle_cust: 0.0040 - 2s/epoch - 1s/step\n",
      "Epoch 45/50\n",
      "2/2 - 3s - loss: 6.3112e-04 - mae: 0.0145 - rmsle_cust: 0.0018 - val_loss: 0.0075 - val_mae: 0.0545 - val_rmsle_cust: 0.0040 - 3s/epoch - 1s/step\n",
      "Epoch 46/50\n",
      "2/2 - 3s - loss: 5.9442e-04 - mae: 0.0139 - rmsle_cust: 0.0017 - val_loss: 0.0074 - val_mae: 0.0542 - val_rmsle_cust: 0.0040 - 3s/epoch - 2s/step\n",
      "Epoch 47/50\n",
      "2/2 - 3s - loss: 5.6435e-04 - mae: 0.0136 - rmsle_cust: 0.0016 - val_loss: 0.0075 - val_mae: 0.0542 - val_rmsle_cust: 0.0040 - 3s/epoch - 1s/step\n",
      "Epoch 48/50\n",
      "2/2 - 4s - loss: 5.3317e-04 - mae: 0.0131 - rmsle_cust: 0.0016 - val_loss: 0.0075 - val_mae: 0.0541 - val_rmsle_cust: 0.0039 - 4s/epoch - 2s/step\n",
      "Epoch 49/50\n",
      "2/2 - 5s - loss: 5.0449e-04 - mae: 0.0126 - rmsle_cust: 0.0016 - val_loss: 0.0074 - val_mae: 0.0538 - val_rmsle_cust: 0.0039 - 5s/epoch - 3s/step\n",
      "Epoch 50/50\n",
      "2/2 - 4s - loss: 4.7816e-04 - mae: 0.0121 - rmsle_cust: 0.0015 - val_loss: 0.0074 - val_mae: 0.0537 - val_rmsle_cust: 0.0039 - 4s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26415476fd0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 2500\n",
    "epochs = 50\n",
    "# Calculate learning rate decay.\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(dtrain.shape[0] / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.007, 0.0005\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "\n",
    "cnn_model_ = cnn_model(lr=lr_init, decay=lr_decay)\n",
    "print(\"Fitting CNN model to training data...\")\n",
    "cnn_model_.fit(\n",
    "        X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_test, dtest.target), verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 37ms/step\n",
      "RMSLE error for CNN Based Model on Test Data: 0.22003676292471444\n",
      "RMSE error for CNN Based Model on Test Data: 7.141579505698121\n"
     ]
    }
   ],
   "source": [
    "val_preds = cnn_model_.predict(X_test)\n",
    "val_preds = target_scaler.inverse_transform(val_preds)\n",
    "val_preds = np.exp(val_preds)+1\n",
    "\n",
    "# mean_absolute_error, mean_squared_log_error.\n",
    "y_true = np.array(dtest.mrp.values)\n",
    "y_pred = val_preds[:,0]\n",
    "v_rmsle = rmsle(y_true, y_pred)\n",
    "v_rmse = mean_squared_error(y_true, y_pred , squared=False)\n",
    "print(\"RMSLE error for CNN Based Model on Test Data: \"+str(v_rmsle))\n",
    "print(\"RMSE error for CNN Based Model on Test Data: \"+str(v_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>product_category_wide</th>\n",
       "      <th>mrp</th>\n",
       "      <th>clean_description</th>\n",
       "      <th>seq_description</th>\n",
       "      <th>seq_product_name</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>logo to go low rise thong 631581</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>22.00</td>\n",
       "      <td>soft  sheer lace wraps around waist lightweigh...</td>\n",
       "      <td>[18, 72, 1, 1261, 521, 161, 264, 20, 8, 83, 90]</td>\n",
       "      <td>[35, 87, 65, 21, 16, 8, 1980]</td>\n",
       "      <td>-0.468620</td>\n",
       "      <td>26.587652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>lace plunge bra</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>35.00</td>\n",
       "      <td>elegant black plunge bra prettified gorgeous l...</td>\n",
       "      <td>[488, 133, 80, 2, 2973, 238, 1, 711, 109, 324,...</td>\n",
       "      <td>[1, 80, 2]</td>\n",
       "      <td>-0.268490</td>\n",
       "      <td>25.817434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>classic mesh triangle bralette</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>54.00</td>\n",
       "      <td>classic silhouettes airy stretch mesh</td>\n",
       "      <td>[100, 682, 616, 34, 36]</td>\n",
       "      <td>[100, 36, 68, 19]</td>\n",
       "      <td>-0.079174</td>\n",
       "      <td>47.979275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>happy unlined bandeau bra</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26.95</td>\n",
       "      <td>hello  happy bras  happiness feeling like real...</td>\n",
       "      <td>[240, 52, 92, 148, 269, 150, 12, 235, 360, 52,...</td>\n",
       "      <td>[52, 169, 312, 2]</td>\n",
       "      <td>-0.381549</td>\n",
       "      <td>27.209633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>b.provocative contrast-lace bra 951222</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>40.00</td>\n",
       "      <td>flattering sheer nude panels decorated intrica...</td>\n",
       "      <td>[215, 72, 393, 781, 999, 571, 1250, 325, 3311,...</td>\n",
       "      <td>[67, 686, 216, 1, 2, 3892]</td>\n",
       "      <td>-0.210396</td>\n",
       "      <td>38.513603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                product_name  brand_name  product_category_wide    mrp                                  clean_description                                    seq_description               seq_product_name    target  predicted_price\n",
       "3619        logo to go low rise thong 631581           6                      7  22.00  soft  sheer lace wraps around waist lightweigh...    [18, 72, 1, 1261, 521, 161, 264, 20, 8, 83, 90]  [35, 87, 65, 21, 16, 8, 1980] -0.468620        26.587652\n",
       "3444                         lace plunge bra          12                      4  35.00  elegant black plunge bra prettified gorgeous l...  [488, 133, 80, 2, 2973, 238, 1, 711, 109, 324,...                     [1, 80, 2] -0.268490        25.817434\n",
       "2517          classic mesh triangle bralette           6                      3  54.00             classic silhouettes airy stretch mesh                             [100, 682, 616, 34, 36]              [100, 36, 68, 19] -0.079174        47.979275\n",
       "3076               happy unlined bandeau bra           0                      4  26.95  hello  happy bras  happiness feeling like real...  [240, 52, 92, 148, 269, 150, 12, 235, 360, 52,...              [52, 169, 312, 2] -0.381549        27.209633\n",
       "5635  b.provocative contrast-lace bra 951222           1                      4  40.00  flattering sheer nude panels decorated intrica...  [215, 72, 393, 781, 999, 571, 1250, 325, 3311,...     [67, 686, 216, 1, 2, 3892] -0.210396        38.513603"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the price.\n",
    "preds = lstm_model.predict(X_test, batch_size=BATCH_SIZE)\n",
    "preds = target_scaler.inverse_transform(preds)\n",
    "preds = np.exp(preds)-1\n",
    "dtest[\"predicted_price\"] = preds\n",
    "dtest.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
